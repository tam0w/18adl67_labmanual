{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Program 4\n",
    "\n",
    "Train a regularized logistic regression classifier on the iris dataset (https://archive.ics.uci.edu/ml/machine-learning-databases/iris/ or the inbuilt iris dataset) using sklearn.Train the model with the following hyperparameter C = 1e4 and report the best classification accuracy.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "\n",
    "\"Imports complete.\"\n",
    "iris = load_iris()\n",
    "y = iris.target\n",
    "X = iris.data\n",
    "class_names = iris.target_names\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = train_test_split(X,y,test_size = 0.2, random_state =42)\n",
    "\n",
    "\"Training and test splits have been made\"\n",
    "scaler = StandardScaler()\n",
    "Xtrain = scaler.fit_transform(Xtrain)\n",
    "Xtest = scaler.transform(Xtest)\n",
    "\n",
    "\"Data has been rescaled\"\n",
    "C = 1e4\n",
    "model = LogisticRegression(C=C, penalty='l2',max_iter=1000,solver='liblinear')\n",
    "model.fit(Xtrain,ytrain)\n",
    "ypred = model.predict(Xtest)\n",
    "\"Model created.\"\n",
    "print(\"Accuracy based on test set:\", accuracy_score(ypred,ytest))\n",
    "cm = confusion_matrix(ytest,ypred)\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(cm,annot=True,cmap='Greys',xticklabels=class_names,yticklabels=class_names,fmt='d')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.show()\n",
    "sample = np.array([[5,3,1,0]])\n",
    "ysample = model.predict(sample)\n",
    "predclass = class_names[ysample[0]]\n",
    "print(\"Predicted Class:\" ,class_names[ysample[0]])\n",
    "\n",
    "model_dict = {\n",
    "    \"coef\": model.coef_.tolist(),\n",
    "    \"intercept\": model.intercept_.tolist(),\n",
    "    \"classes\": iris.target_names.tolist(),\n",
    "    \"attributes\": iris.feature_names\n",
    "}\n",
    "\n",
    "with open(\"model.json\",'w') as jsonlover:\n",
    "    json.dump(model_dict,jsonlover)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Program 5\n",
    "\n",
    "Train an SVM classifier on the iris dataset using sklearn. Try different kernels and the associated hyperparameters. Train model with the following set hyperparameters RBF-kernel, gamma=0.5, onevs-rest classifier, no-feature-normalization. Also try C=0.01,1,10C=0.01,1,10. For the above set of hyperparameters, find the best classification accuracy along with total number of support vectors on the test data.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "class_names = iris.target_names\n",
    "Xtrain,Xtest,ytrain,ytest = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "gammas = [0.5]\n",
    "Cc = [0.01,1,10]\n",
    "kernels = ['rbf']\n",
    "\n",
    "best_accuracy = 0\n",
    "best_sup_vectors = 0\n",
    "colors = ['Blues','Reds','Greys']\n",
    "\n",
    "for kernel in kernels:\n",
    "    for gamma in gammas:\n",
    "        for colour_no,C in enumerate(Cc):\n",
    "            colour = colors[colour_no]\n",
    "            model = SVC(kernel=kernel,gamma=gamma,C=C)\n",
    "            model.fit(Xtrain,ytrain)\n",
    "            ypred = model.predict(Xtest)\n",
    "            print(\"Model Info: \\nKernel, Gamma, C\")\n",
    "            print(kernel,gamma,C,sep='\\t\\t')\n",
    "\n",
    "            accuracy=accuracy_score(ytest,ypred)\n",
    "\n",
    "            print(\"Accuracy:\",accuracy)\n",
    "            print('-----------------')\n",
    "\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_sup_vectors = model.n_support_.sum()\n",
    "\n",
    "            cm = confusion_matrix(ytest,ypred)\n",
    "            plt.figure(figsize=(4,4))\n",
    "            sns.heatmap(cm,annot=True,cmap=colour,fmt='d')\n",
    "            plt.xlabel('Actual Class')\n",
    "            plt.ylabel('Predicted Class')\n",
    "            plt.show()\n",
    "\n",
    "print(\"Best Accuracy AND Number of Support Vectors:\",best_sup_vectors,\"and\",best_accuracy)\n",
    "\n",
    "with open('model.pkl','wb') as pkl:\n",
    "    pickle.dump(model,pkl)\n",
    "\n",
    "with open('model.pkl','rb') as pkl:\n",
    "    loaded_model = pickle.load(pkl)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Program 6\n",
    "\n",
    "Consider the following dataset. Write a program to demonstrate the working of the decision tree based ID3 algorithm.\n",
    "Headers = price, maintanence, capacity, airbag, profitable\n",
    "                        [['low', 'low', 1, 'no', 'no'],\n",
    "                                    ['low', 'low', 2, 'no', 'no'],\n",
    "                                    ['med', 'low', 2, 'yes', 'yes'],\n",
    "                                    ['high', 'med', 2, 'yes', 'yes'],\n",
    "                                    ['high', 'high', 3, 'yes', 'yes'],\n",
    "                                    ['high', 'high', 3, 'no', 'no'],\n",
    "                                    ['med', 'high', 3, 'yes', 'no']]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "def build(dt,cl,attributes):\n",
    "    if len(set(cl)) == 1:\n",
    "        return cl[0]\n",
    "\n",
    "    if len(attributes) == 0:\n",
    "        return majority(cl)\n",
    "\n",
    "    best_attr = get_best_attribute(dt,cl,attributes)\n",
    "    tree = {best_attr:{}}\n",
    "    attribute_values = set(sample[attributes.index(best_attr)] for sample in dt)\n",
    "\n",
    "    for value in attribute_values:\n",
    "        subset = [sample for sample in dt if sample[attributes.index(value)] == value]\n",
    "        subset_class_labels = [sample[-1] for sample in subset]\n",
    "        remaining_attributes = attributes[:]\n",
    "        remaining_attributes.remove(best_attribute)\n",
    "        tree[best_attribute][value] = build_decision_tree(subset, remaining_attributes, subset_class_labels)\n",
    "    return tree\n",
    "\n",
    "def majority(cl):\n",
    "    yes = cl.count('yes')\n",
    "    no = cl.count('no')\n",
    "    if yes >= no:\n",
    "        return \"Yes\"\n",
    "    else:\n",
    "        return \"No\"\n",
    "def entropy(cl):\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "def get_best_attribute(dt,cl,attributes):\n",
    "    gains = [gain(dt,cl,attribute) for attribute in range(len(attributes))]\n",
    "    best_index = gains.index(max(gains))\n",
    "    return attributes[best_index]\n",
    "\n",
    "dt = [['low', 'low', 1, 'no', 'no'],['low', 'low', 2, 'no', 'no'],['med', 'low', 2, 'yes', 'yes'],['high', 'med', 2, 'yes', 'yes'],['high', 'high', 3, 'yes', 'yes'],['high', 'high', 3, 'no', 'no'],['med', 'high', 3, 'yes', 'no']]\n",
    "cl = [row[-1] for row in dt]\n",
    "attributes = ['Price', 'maintenance', 'capacity', 'airbag']\n",
    "\n",
    "tree = build(dt,cl,attributes)\n",
    "\n",
    "test = ['low', 'low', 1, 'no']\n",
    "predval = predict(test,tree)\n",
    "\n",
    "print(\"Prediction for given sample:\",predval,\"\\nGiven Sample:\",test)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Program 7\n",
    "Consider the dataset spiral.txt (https://bit.ly/2Lm75Ly). The first two columns in the dataset corresponds to the co-ordinates of each data point. The third column corresponds to the actual cluster label. Compute the rand index for the following methods: 1. K – means Clustering 2. Single – link Hierarchical Clustering 3. Complete link hierarchical clustering. Also visualize the dataset and which algorithm will be able to recover the true clusters.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "df = pd.read_csv('Spiral.txt', skiprows=1,header=None, delimiter='\\t')\n",
    "df.columns = ['f1','f2','labels']\n",
    "X = df[['f1','f2']].astype(float).values\n",
    "y = df['labels'].values\n",
    "\n",
    "km = KMeans(random_state=42,n_clusters=3)\n",
    "ypredkm = km.fit_predict(X,y)\n",
    "kmscore = adjusted_rand_score(y,ypredkm)\n",
    "\n",
    "sg = AgglomerativeClustering(n_clusters=3, linkage='single')\n",
    "ypredsg = sg.fit_predict(X,y)\n",
    "sgscore = adjusted_rand_score(y,ypredsg)\n",
    "\n",
    "cm = AgglomerativeClustering(n_clusters=3, linkage='complete')\n",
    "ypredcm = cm.fit_predict(X,y)\n",
    "cmscore = adjusted_rand_score(y,ypredcm)\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(15,7))\n",
    "ax[0].scatter(X[:,0],X[:,1],c=ypredkm)\n",
    "ax[0].set_title(f'Kmeans Clustering RI Score:{kmscore:.3f}')\n",
    "\n",
    "ax[1].scatter(X[:,0],X[:,1],c=ypredsg)\n",
    "ax[1].set_title(f'SL Clustering RI Score:{sgscore:.3f}')\n",
    "\n",
    "ax[2].scatter(X[:,0],X[:,1],c=ypredcm)\n",
    "ax[2].set_title(f'CL Clustering RI Score:{cmscore:.3f}')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Program 8\n",
    "\n",
    "Implement a k-Nearest Neighbor algorithm to classify the iris dataset. Print out both correct and wrong predictions.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "labels = iris.target_names\n",
    "\n",
    "k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,random_state=42,test_size=0.2)\n",
    "\n",
    "knn.fit(xtrain,ytrain)\n",
    "\n",
    "ypred = knn.predict(xtest)\n",
    "\n",
    "for i in range(len(xtest)):\n",
    "    pred = labels[ypred[i]]\n",
    "    actual = labels[ytest[i]]\n",
    "    result = \"Correct\" if pred == actual else \"FALSE\"\n",
    "    print(f'The prediction is {pred} and the actual value is {actual} \\n{result}')\n",
    "    print('------------------------------------- \\n')\n",
    "\n",
    "print(\"Accuracy is:\",accuracy_score(ytest,ypred))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
